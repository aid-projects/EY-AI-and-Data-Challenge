{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "afd0ad9f-c4a5-453e-a40e-cb0a1f243804",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "!pip install uv\n!uv pip install  -r requirements.txt ",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f84f8bc3-07d7-45f1-9db5-4de285eb345f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\n\n\nsession = get_active_session()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "95040bbf-1848-45f0-aab4-1d8ba434f934",
      "metadata": {
        "language": "python"
      },
      "source": "# Stage or location to check\nstage_location = \"\"\"snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge\"/versions/live/terraclimate_training_soil_data/\"\"\"\n\n# Run LIST command to get files in the stage\ndf_files = session.sql(f\"LIST '{stage_location}'\")\n\n# Count the number of files\nfile_count = df_files.count()\n\ndf_files.show()\n\nprint(f\"Number of files in {stage_location}: {file_count}\")\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ce63f2e7-97a0-4627-9e90-c0e27a0d29a3",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nfrom pathlib import Path\nimport zipfile\n\nfolder_name = \"terraclimate_training_vpd_data\"\n\nsource_dir = Path(f\"./{folder_name}/\")      # folder containing 60 CSVs\nzip_path   = Path(f\"/tmp/{folder_name}.zip\")\n\ncsv_files = sorted(source_dir.glob(\"*.csv\"))  # or \"**/*.csv\" for recursive\n\nif not csv_files:\n    raise FileNotFoundError(f\"No CSV files found in {source_dir}\")\n\nwith zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n    for file in csv_files:\n        zf.write(file, arcname=file.name)\n\nprint(f\"Created: {zip_path} ({len(csv_files)} files)\")\n\nsession.sql(f\"\"\"\n    PUT file:///tmp/{folder_name}.zip\n    'snow://workspace/USER$.PUBLIC.\"EY-AI-and-Data-Challenge\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6222361a-4508-4158-8b43-331eac2384a2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pathlib import Path\nimport pandas as pd\n\n\nsource_data = ['terraclimate']\nterraclimate_variables = ['aet', 'pet', 'q', 'ppt', 'soil', 'tmax', 'tmin', 'vpd']\n\n\nfor i in range(len(source_data)):\n    folder_name = source_data[i]\n    print(folder_name)\n    source_dir = Path(f\"./data/{folder_name}/\")  \n\n    csv_files = sorted(source_dir.glob(\"*.csv\"))\n\n    #training_df = pd.DataFrame()\n    training_df = pd.read_csv('data/water_quality_training_dataset.csv')\n\n    for col in training_df.columns:\n        training_df = training_df.rename(columns={col: col.lower()})\n\n    submission_df = pd.read_csv('data/submissions_template.csv')\n\n    for col in submission_df.columns:\n        submission_df = submission_df.rename(columns={col: col.lower()})\n    \n    for i in range(len(csv_files)):\n\n    #for i in range(2):\n\n        print(csv_files[i])\n\n        temp_df = pd.read_csv(f\"{csv_files[i]}\")\n\n        for col in temp_df.columns:\n            temp_df = temp_df.rename(columns={col: col.lower()})\n\n        \n        if 'training' in str(csv_files[i]):\n\n            training_df = training_df.merge(temp_df, on=['Latitude', 'Longitude', 'Sample Date'], how='inner')\n            \n        elif 'validation' in str(csv_files[i]):\n            \n            submission_df = submission_df.merge(temp_df, on=['Latitude', 'Longitude', 'Sample Date'], how='inner'        \n\n            ",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b421d8f-fac8-4efd-9152-538711701230",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "display(main_df)",
      "outputs": [],
      "execution_count": null
    }
  ]
}