{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b92d672a-a1ff-4806-9dce-5f8c9a4f051b",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell1"
      },
      "source": "# Benchmark Evaluation Notebook"
    },
    {
      "cell_type": "markdown",
      "id": "57447c9d-ceca-4a26-8066-2dca61e0e224",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell6"
      },
      "source": "## Load In Dependencies\nThe following code installs the required Python libraries (found in the requirements.txt file) in the Snowflake environment to allow successful execution of the remaining notebook code. After running this code for the first time, it is required to “restart” the kernal so the Python libraries are available in the environment. This is done by selecting the “Connected” menu above the notebook (next to “Run all”) and selecting the “restart kernal” link. Subsequent runs of the notebook do not require this “restart” process."
    },
    {
      "cell_type": "code",
      "id": "7d7871c0-d5f3-45da-a289-3d19db67bf15",
      "metadata": {
        "language": "python",
        "name": "cell58",
        "ExecuteTime": {
          "end_time": "2026-02-08T04:39:08.423357Z",
          "start_time": "2026-02-08T04:39:08.420717Z"
        }
      },
      "source": "# !pip install uv\n# !uv pip install  -r requirements.txt",
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "id": "b53ef74f-52ba-4c63-b412-2f4432408d04",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell8",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:38:17.897556Z",
          "start_time": "2026-02-08T21:38:16.270081Z"
        }
      },
      "source": "# import snowflake\n# from snowflake.snowpark.context import get_active_session\n# session = get_active_session()\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\n# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\nimport xarray as xr\n\n# Geospatial raster data handling with CRS support\nimport rioxarray as rxr\n\n# Raster operations and spatial windowing\nimport rasterio\nfrom rasterio.windows import Window\n\n# Feature preprocessing and data splitting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import cKDTree\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n# Planetary Computer tools for STAC API access and authentication\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\n\nfrom datetime import date\nfrom tqdm import tqdm\nimport os",
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "codeCollapsed": true
      },
      "cell_type": "markdown",
      "source": "## Input Params",
      "id": "c55c868594617c5c"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:35.898877Z",
          "start_time": "2026-02-08T21:49:35.895659Z"
        },
        "language": "python"
      },
      "cell_type": "code",
      "source": "feature_to_test = 'NDTI'\nfeature_dataset_path = \"../development/landsat_features_training_all_bands_with_index.csv\"",
      "id": "c81eb47d125cdf98",
      "outputs": [],
      "execution_count": 25
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-08T21:46:07.553574Z",
          "start_time": "2026-02-08T21:46:07.536692Z"
        },
        "language": "python"
      },
      "cell_type": "code",
      "source": "train_features = None\nif feature_to_test is not None:\n    train_features = pd.read_csv(feature_dataset_path)\n    display(train_features.head(5))",
      "id": "68ecb96c65c88e7",
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "id": "fdfcbb20-8dff-401a-9f55-ed5d08eb6b60",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell9"
      },
      "source": "## Response Variable"
    },
    {
      "cell_type": "code",
      "id": "892acc46-4840-489a-8c69-ecf4123d2a31",
      "metadata": {
        "language": "python",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:39:53.870321Z",
          "start_time": "2026-02-08T21:39:53.859380Z"
        }
      },
      "source": "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\nWater_Quality_df[\"sample_location_group\"] = Water_Quality_df.groupby(['Longitude', 'Latitude']).ngroup()\n# display(Water_Quality_df.head(5))",
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "id": "61676d8d-7141-4682-9687-850e56e3ef28",
      "metadata": {
        "language": "python",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:40:22.646040Z",
          "start_time": "2026-02-08T21:40:22.632385Z"
        }
      },
      "source": "landsat_train_features = pd.read_csv(\"landsat_features_training.csv\")\nlandsat_train_features['NDMI'] = landsat_train_features['NDMI'].astype(float)\nlandsat_train_features['MNDWI'] = landsat_train_features['MNDWI'].astype(float)\n# display(landsat_train_features.head(5))",
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-08T21:40:23.309078Z",
          "start_time": "2026-02-08T21:40:23.292189Z"
        },
        "language": "python"
      },
      "cell_type": "code",
      "source": "Terraclimate_df = pd.read_csv(\"../terraclimate_features_training.csv\")\n# display(Terraclimate_df.head(5))",
      "id": "65e66f7bd6be1583",
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "id": "7b42801e-e7b9-4b17-b4e4-f65fd971decc",
      "metadata": {
        "language": "python",
        "name": "cell21",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:47:33.947733Z",
          "start_time": "2026-02-08T21:47:33.944711Z"
        }
      },
      "source": "# Combine two datasets vertically (along columns) using pandas concat function.\ndef combine_two_datasets(dataset1,dataset2,dataset3):\n    '''\n    Returns a  vertically concatenated dataset.\n    Attributes:\n    dataset1 - Dataset 1 to be combined\n    dataset2 - Dataset 2 to be combined\n    '''\n\n    data = pd.concat([dataset1,dataset2,dataset3], axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data\n\n# Combine two datasets vertically (along columns) using pandas concat function.\ndef combine_dataset_list(dataset_list):\n    '''\n    Returns a  vertically concatenated dataset.\n    Attributes:\n    dataset_list - List of datasets to be combined in order\n    '''\n\n    data = pd.concat(dataset_list, axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data",
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "id": "c75dffde-a8e3-4a6e-bbab-bf0d8aac7bfe",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell22",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:48:24.270152Z",
          "start_time": "2026-02-08T21:48:24.259779Z"
        }
      },
      "source": "wq_data = None\nif train_features is None:\n    # Combining ground data and final data into a single dataset.\n    wq_data = combine_two_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)\n    display(wq_data.head(5))\nelse:\n    # Combining ground data and final data into a single dataset.\n    wq_data = combine_dataset_list([Water_Quality_df, landsat_train_features, Terraclimate_df, train_features])\n    display(wq_data.head(5))",
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "id": "c4573656-100c-49e7-b3bb-536e0a6290ac",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell23"
      },
      "source": "### Handling Missing Values\n\nBefore model training, missing values in the dataset were carefully handled to ensure data consistency and prevent model bias. Numerical columns were imputed using their median values, maintaining the overall data distribution while minimizing the impact of outliers."
    },
    {
      "cell_type": "code",
      "id": "de7372e4-26c6-4bd8-9d7a-39bc35b01a14",
      "metadata": {
        "language": "python",
        "name": "cell24",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:48:31.162482Z",
          "start_time": "2026-02-08T21:48:31.154027Z"
        }
      },
      "source": "wq_data = wq_data.fillna(wq_data.median(numeric_only=True))\nwq_data.isna().sum()",
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "id": "560a997d-ec88-4ae0-b540-44cd3e5f6cf2",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell25"
      },
      "source": "## Model Building"
    },
    {
      "cell_type": "markdown",
      "id": "8e9f7c65-b3a1-405b-b912-cef4e5157bce",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell26"
      },
      "source": "Now let us select the columns required for our model-building exercise. We will consider only **SWIR22**, **NDMI**, and **MNDWI** from the Landsat data, and **PET** from the TerraClimate dataset as our predictor variables. It does not make sense to use latitude and longitude as predictor variables, as they do not have any direct impact on predicting the water quality parameters."
    },
    {
      "cell_type": "code",
      "id": "35381365-adf1-4702-a99d-5cec95812ff9",
      "metadata": {
        "language": "python",
        "name": "cell27",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:39.293698Z",
          "start_time": "2026-02-08T21:49:39.288415Z"
        }
      },
      "source": "# Retaining only the columns for swir22, NDMI, MNDWI, pet, Total Alkalinity, Electrical Conductance and Dissolved Reactive Phosphorus Index in the dataset.\nif feature_to_test is None:\n    wq_data = wq_data[[\"sample_location_group\", 'swir22','NDMI','MNDWI','pet', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']]\nelse:\n    wq_data = wq_data[[\"sample_location_group\", feature_to_test, 'swir22','NDMI','MNDWI','pet', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']]",
      "outputs": [],
      "execution_count": 26
    },
    {
      "metadata": {
        "language": "python",
        "name": "cell31",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:40.712462Z",
          "start_time": "2026-02-08T21:49:40.709456Z"
        }
      },
      "cell_type": "code",
      "source": "def split_data(X, y, test_size=0.3, random_state=42):\n    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n\ndef scale_data(X_train, X_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled, scaler\n\ndef train_model(X_train_scaled, y_train):\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    return model\n\ndef evaluate_model(model, X_scaled, y_true, dataset_name=\"Test\"):\n    y_pred = model.predict(X_scaled)\n    r2 = r2_score(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    # print(f\"\\n{dataset_name} Evaluation:\")\n    # print(f\"R²: {r2:.3f}\")\n    # print(f\"RMSE: {rmse:.3f}\")\n    return y_pred, r2, rmse",
      "id": "c7e68f6e-1679-467f-803c-e819d654bbab",
      "outputs": [],
      "execution_count": 27
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:41.938166Z",
          "start_time": "2026-02-08T21:49:41.933351Z"
        },
        "language": "python"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n\ndef run_groupkfold_cv(X, y, groups, n_splits=5, param_name=\"Parameter\"):\n    gkf = GroupKFold(n_splits=n_splits)\n    fold_results = []\n\n    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n        # print(f\"\\n=== Fold {fold+1} ===\")\n\n        # Split\n        X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n\n        # Scale\n        X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n\n        # Train\n        model = train_model(X_train_scaled, y_train)\n\n        # Evaluate (in-sample)\n        y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n\n        # Evaluate (out-sample)\n        y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n\n        fold_results.append((r2_train, rmse_train, r2_test, rmse_test))\n\n    df_results_kfold = pd.DataFrame(fold_results, columns=['R2_Train', 'RMSE_Train', 'R2_Test', 'RMSE_Test']).reset_index().rename(columns={\"index\": \"fold\"})\n    df_results_kfold['Parameter'] = param_name\n    df_results_kfold['Features'] = ', '.join([col for col in X.columns if col != 'sample_location_group'])\n    df_results_kfold = df_results_kfold[['Parameter', 'Features', 'R2_Train', 'RMSE_Train', 'R2_Test', 'RMSE_Test']]\n\n    return df_results_kfold",
      "id": "a3f03921f4a7e450",
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "id": "39cec372-283e-404a-a989-714969c53b0d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell32"
      },
      "source": "## Model Workflow (Pipeline)\n\nThe complete model development process follows a structured pipeline to ensure consistency, reproducibility, and clarity. Each stage in the workflow is modularized into independent functions that can be reused for different water quality parameters. This modular approach streamlines the process and makes the workflow easily adaptable to new datasets or parameters in the future.\n\nThe pipeline automates the sequence of steps — from data preparation to evaluation — for each target parameter. The same set of predictor variables is used, while the response variable changes for each of the three targets: *Total Alkalinity (TA)*, *Electrical Conductance (EC)*, and *Dissolved Reactive Phosphorus (DRP)*. By maintaining a consistent framework, comparisons across models remain fair and interpretable."
    },
    {
      "cell_type": "code",
      "id": "40808f99-8014-4746-91ae-5b64c61e04a7",
      "metadata": {
        "language": "python",
        "name": "cell33",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:44.460158Z",
          "start_time": "2026-02-08T21:49:44.455956Z"
        }
      },
      "source": "def run_pipeline(X, y, param_name=\"Parameter\"):\n    # print(f\"\\n{'='*60}\")\n    # print(f\"Training Model for {param_name}\")\n    # print(f\"{'='*60}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = split_data(X, y)\n    \n    # Scale\n    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n    \n    # Train\n    model = train_model(X_train_scaled, y_train)\n    \n    # Evaluate (in-sample)\n    y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n    \n    # Evaluate (out-sample)\n    y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n    \n    # Return summary\n    results = {\n        \"Parameter\": param_name,\n        \"Features\": ', '.join([col for col in X.columns if col != 'sample_location_group']),\n        \"R2_Train\": r2_train,\n        \"RMSE_Train\": rmse_train,\n        \"R2_Test\": r2_test,\n        \"RMSE_Test\": rmse_test\n    }\n    return model, scaler, pd.DataFrame([results])",
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "id": "1783a30e-ee66-4c50-a957-b67296e9328c",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell34"
      },
      "source": "### Model Training and Evaluation for Each Parameter"
    },
    {
      "cell_type": "markdown",
      "id": "ed5f39fd-a577-4eff-9fa5-caa9d7f2fcda",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell35"
      },
      "source": "In this step, we apply the complete modeling pipeline to each of the three selected water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. The input feature set (`X`) remains the same across all three models, while the target variable (`y`) changes for each parameter. \n\nFor every parameter, the `run_pipeline()` function is executed, which handles data preprocessing, model training, and both in-sample and out-of-sample evaluation. This ensures a consistent workflow and allows for a fair comparison of model performance across different water quality indicators."
    },
    {
      "cell_type": "code",
      "id": "d2d5f62b-585c-45e0-8fa9-73a5fa1248f8",
      "metadata": {
        "language": "python",
        "name": "cell36",
        "ExecuteTime": {
          "end_time": "2026-02-08T21:49:54.255513Z",
          "start_time": "2026-02-08T21:49:48.456026Z"
        }
      },
      "source": "X = wq_data.drop(columns=['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus'])\n\ny_TA = wq_data['Total Alkalinity']\ny_EC = wq_data['Electrical Conductance']\ny_DRP = wq_data['Dissolved Reactive Phosphorus']\n\nmodel_TA, scaler_TA, results_TA = run_pipeline(X, y_TA, \"Total Alkalinity\")\nmodel_EC, scaler_EC, results_EC = run_pipeline(X, y_EC, \"Electrical Conductance\")\nmodel_DRP, scaler_DRP, results_DRP = run_pipeline(X, y_DRP, \"Dissolved Reactive Phosphorus\")\n\ndf_results = pd.concat([results_TA, results_EC, results_DRP], axis=0)\ndisplay(df_results)",
      "outputs": [],
      "execution_count": 30
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-08T21:50:25.446764Z",
          "start_time": "2026-02-08T21:49:54.273600Z"
        },
        "language": "python"
      },
      "cell_type": "code",
      "source": "groups = wq_data['sample_location_group']   # or station_id, river_id, etc.\nresults_TA = run_groupkfold_cv(X, y_TA, groups, param_name=\"Total Alkalinity\")\nresults_EC = run_groupkfold_cv(X, y_EC, groups, param_name=\"Electrical Conductance\")\nresults_DRP = run_groupkfold_cv(X, y_DRP, groups, param_name=\"Dissolved Reactive Phosphorus\")\n\ndf_results = pd.concat([results_TA, results_EC, results_DRP], axis=0)\ndisplay(df_results)\n\ndf_result_mean = df_results.groupby(['Parameter', 'Features']).mean()#.rename(columns={'R2': 'R2 (mean)', 'RMSE': 'RMSE (mean)'})\ndisplay(df_result_mean.sort_values('Parameter', ascending=False))",
      "id": "da4948854d76a227",
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "id": "644a854c-a8af-411e-b5af-e78d064d80a1",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell37"
      },
      "source": "### Model Performance Summary"
    },
    {
      "cell_type": "markdown",
      "id": "23b4c7a8-c192-469f-8a18-972f4900da2b",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell38"
      },
      "source": "After training and evaluating the models for each water quality parameter, the individual performance metrics are combined into a single summary table. This table consolidates the R² and RMSE values for both in-sample and out-of-sample evaluations, enabling an easy comparison of model performance across Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. \n\nSuch a summary provides a quick overview of how well each model captures the variability in each parameter and highlights any differences in predictive accuracy."
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c7f3a047-a05c-4369-8a84-5b287f1ff272",
      "metadata": {
        "language": "python",
        "name": "cell39"
      },
      "outputs": [],
      "source": "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\nresults_summary"
    },
    {
      "cell_type": "markdown",
      "id": "b5277b08-d7bc-4b7c-91bf-26fa19795f56",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell41"
      },
      "source": "## Submission (NO NOT USE BELOW)"
    },
    {
      "cell_type": "markdown",
      "id": "f59c5dde-8a39-4e16-bdd9-93ce024850d2",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell42"
      },
      "source": "Once you are satisfied with your model’s performance, you can proceed to make predictions for unseen data. To do this, use your trained model to estimate the concentrations of the target water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus — for a set of test locations provided in the **Submission_template.csv** file. \n\nThe predicted results can then be uploaded to the challenge platform for evaluation."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1475b7c2-6562-4274-9bd6-98b305010351",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "test_file = pd.read_csv(\"submission_template.csv\")\ndisplay(test_file.head(5))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e85fe2-7570-432e-b1f2-bc16dda08ab4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "landsat_val_features = pd.read_csv(\"landsat_features_validation.csv\")\ndisplay(landsat_val_features.head(5))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e53ead-e1b6-4d7d-93bb-12505fbb2ead",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "Terraclimate_val_df = pd.read_csv(\"terraclimate_features_validation.csv\")\ndisplay(Terraclimate_val_df.head(5))"
    },
    {
      "cell_type": "markdown",
      "id": "1feacaed-272c-4812-8c14-d2bd6a8d48f1",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell44"
      },
      "source": "Similarly, participants can use the **Landsat** and **TerraClimate** data extraction demonstration notebooks to produce feature CSVs for their **validation** data. For convenience, we have already computed and saved example validation outputs as `landsat_features_val_V3.csv` and `Terraclimate_val_df_v3.csv`. \n\nParticipants should save their own extracted files in the same format and column schema; doing so will allow this benchmark notebook to load the validation features directly and run smoothly."
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d1dabb48-7f82-4acf-b509-21cc15a5a4e0",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell47"
      },
      "outputs": [],
      "source": "#Consolidate all the extracted bands and features in a single dataframe\nval_data = pd.DataFrame({\n    'Longitude': landsat_val_features['Longitude'].values,\n    'Latitude': landsat_val_features['Latitude'].values,\n    'Sample Date': landsat_val_features['Sample Date'].values,\n    'nir': landsat_val_features['nir'].values,\n    'green': landsat_val_features['green'].values,\n    'swir16': landsat_val_features['swir16'].values,\n    'swir22': landsat_val_features['swir22'].values,\n    'NDMI': landsat_val_features['NDMI'].values,\n    'MNDWI': landsat_val_features['MNDWI'].values,\n    'pet': Terraclimate_val_df['pet'].values,\n})"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5c41d268-0657-490b-94f3-8ffeb67c2265",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell48"
      },
      "outputs": [],
      "source": "# Impute the missing values\nval_data = val_data.fillna(val_data.median(numeric_only=True))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3126bf77-fb54-4609-a09c-8e36b496d108",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell49"
      },
      "outputs": [],
      "source": "# Extracting specific columns (swir22, NDMI, MNDWI, pet) from the validation dataset\nsubmission_val_data=val_data.loc[:,['swir22','NDMI','MNDWI','pet']]\ndisplay(submission_val_data.head())"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d7b033c7-3d5f-4179-b8f8-182f8caad0dc",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell50"
      },
      "outputs": [],
      "source": "submission_val_data.shape"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "87b59132-ff14-421e-b37b-472a0adcd9da",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell51"
      },
      "outputs": [],
      "source": "# --- Predicting for Total Alkalinity ---\nX_sub_scaled_TA = scaler_TA.transform(submission_val_data)\npred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n\n# --- Predicting for Electrical Conductance ---\nX_sub_scaled_EC = scaler_EC.transform(submission_val_data)\npred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n\n# --- Predicting for Dissolved Reactive Phosphorus ---\nX_sub_scaled_DRP = scaler_DRP.transform(submission_val_data)\npred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "398e375c-60cc-4fa5-a697-ae12fdab300c",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell52"
      },
      "outputs": [],
      "source": "submission_df = pd.DataFrame({\n    'Longitude': test_file['Longitude'].values,\n    'Latitude': test_file['Latitude'].values,\n    'Sample Date': test_file['Sample Date'].values,\n    'Total Alkalinity': pred_TA_submission,\n    'Electrical Conductance': pred_EC_submission,\n    'Dissolved Reactive Phosphorus': pred_DRP_submission\n})"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "46e1c4fa-e49f-40cf-ac10-729b82c4b37b",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell53"
      },
      "outputs": [],
      "source": "#Displaying the sample submission dataframe\ndisplay(submission_df.head())"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0d3a8c41-dba2-43e4-b84c-a50a096980e7",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell54"
      },
      "outputs": [],
      "source": "#Dumping the predictions into a csv file.\nsubmission_df.to_csv(\"/tmp/submission.csv\",index = False)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc2ba55-0dd6-43ab-902d-6adbfdfaca2c",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "session.sql(f\"\"\"\n    PUT file:///tmp/submission.csv\n    snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")"
    },
    {
      "cell_type": "markdown",
      "id": "9b7af545-7a55-4b59-9edc-bc43f47bffd5",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell55"
      },
      "source": "### Upload submission file on platform\n\nUpload the `submission.csv` file on the challenge platform to generate your score on the leaderboard."
    },
    {
      "cell_type": "markdown",
      "id": "b7ab09ba-3b69-4a2a-a56e-2dbf084e0c56",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell57"
      },
      "source": "## Conclusion\n\nNow that you have learned a basic approach to model training, it’s time to explore your own techniques and ideas! Feel free to modify any of the functions presented in this notebook to experiment with alternative preprocessing steps, feature engineering strategies, or machine learning algorithms. \n\nWe look forward to seeing your enhanced model and the insights you uncover. Best of luck with the challenge!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "lastEditStatus": {
      "authorEmail": "kushijannu14@gmail.com",
      "authorId": "8166278287717",
      "authorName": "KUSHIJANNU12345",
      "lastEditTime": 1765538479641,
      "notebookId": "4b5ewfvmzc3w74qf2h2q",
      "sessionId": "5d2a2269-55b3-4f1a-a29d-f378d3af6df3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}